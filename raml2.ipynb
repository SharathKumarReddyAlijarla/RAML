{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8087cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "img_A_inp = Input((28, 28), name='img_A_inp')\n",
    "img_B_inp = Input((28, 28), name='img_B_inp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa25172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " img_A_inp (InputLayer)         [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " img_B_inp (InputLayer)         [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 64)           259840      ['img_A_inp[0][0]',              \n",
      "                                                                  'img_B_inp[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128)          0           ['sequential_4[0][0]',           \n",
      "                                                                  'sequential_4[1][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            65          ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 268,161\n",
      "Trainable params: 266,241\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n",
      "Number of layers in the CNN: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "\n",
    "def get_mlp_block(units):\n",
    "    return Sequential([Dense(units, activation='relu'),\n",
    "                       BatchNormalization()])\n",
    "\n",
    "DEPTH = 64\n",
    "mlp = Sequential([Flatten(),\n",
    "                  get_mlp_block(DEPTH),\n",
    "                  get_mlp_block(DEPTH*2),\n",
    "                  get_mlp_block(DEPTH*4),\n",
    "                  get_mlp_block(DEPTH*8),\n",
    "                  Dense(64, activation='relu')])\n",
    "\n",
    "feature_vector_A = mlp(img_A_inp)\n",
    "feature_vector_B = mlp(img_B_inp)\n",
    "\n",
    "concat = Concatenate()([feature_vector_A, feature_vector_B])\n",
    "\n",
    "dense = Dense(64, activation='relu')(concat)\n",
    "#dense2= Dense(128,activation='relu')(dense)\n",
    "output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = Model(inputs=[img_A_inp, img_B_inp], outputs=output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Get the number of layers in the model\n",
    "num_layers = len(model.layers)\n",
    "\n",
    "print(\"Number of layers in the CNN:\", num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e79ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_indices = np.random.choice(X_train.shape[0], 100, replace=False)\n",
    "\n",
    "X_train_sample, y_train_sample = X_train[random_indices], y_train[random_indices]\n",
    "\n",
    "X_train_sample.shape, y_train_sample.shape\n",
    "\n",
    "len(X_train_sample) ** 2\n",
    "\n",
    "import itertools\n",
    "\n",
    "def make_paired_dataset(X, y):\n",
    "  X_pairs, y_pairs = [], []\n",
    "\n",
    "  tuples = [(x1, y1) for x1, y1 in zip(X, y)]\n",
    "  \n",
    "  for t in itertools.product(tuples, tuples):\n",
    "    pair_A, pair_B = t\n",
    "    img_A, label_A = t[0]\n",
    "    img_B, label_B = t[1]\n",
    "\n",
    "    new_label = int(label_A == label_B)\n",
    "\n",
    "    X_pairs.append([img_A, img_B])\n",
    "    y_pairs.append(new_label)\n",
    "  \n",
    "  X_pairs = np.array(X_pairs)\n",
    "  y_pairs = np.array(y_pairs)\n",
    "\n",
    "  return X_pairs, y_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77da8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_paired_dataset(X_train_sample, y_train_sample)\n",
    "\n",
    "X_train_pairs, y_train_pairs = make_paired_dataset(X_train_sample, y_train_sample)\n",
    "\n",
    "X_train_pairs.shape, y_train_pairs.shape\n",
    "\n",
    "random_indices = np.random.choice(X_test.shape[0], 50, replace=False)\n",
    "\n",
    "X_test_sample, y_test_sample = X_test[random_indices], y_test[random_indices]\n",
    "\n",
    "X_test_sample.shape, y_test_sample.shape\n",
    "\n",
    "\n",
    "X_test_pairs, y_test_pairs = make_paired_dataset(X_test_sample, y_test_sample)\n",
    "\n",
    "X_test_pairs.shape, y_test_pairs.shape\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936253f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 56ms/step - loss: 0.7924 - accuracy: 0.4857 - val_loss: 0.9410 - val_accuracy: 0.2428\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.4548 - accuracy: 0.8551 - val_loss: 0.7421 - val_accuracy: 0.4596\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3693 - accuracy: 0.8898 - val_loss: 0.6777 - val_accuracy: 0.5832\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3439 - accuracy: 0.8905 - val_loss: 0.6519 - val_accuracy: 0.6488\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3335 - accuracy: 0.8908 - val_loss: 0.6333 - val_accuracy: 0.6940\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3264 - accuracy: 0.8912 - val_loss: 0.6184 - val_accuracy: 0.7124\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 0.3200 - accuracy: 0.8922 - val_loss: 0.5983 - val_accuracy: 0.7376\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 0.3141 - accuracy: 0.8930 - val_loss: 0.5782 - val_accuracy: 0.7540\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 0.3069 - accuracy: 0.8948 - val_loss: 0.5569 - val_accuracy: 0.7716\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 86ms/step - loss: 0.2999 - accuracy: 0.8972 - val_loss: 0.5422 - val_accuracy: 0.7784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=3)\n",
    "\n",
    "model.fit(x=[X_train_pairs[:, 0, :, :], X_train_pairs[:, 1, :, :]],\n",
    "          y=y_train_pairs,\n",
    "          validation_data=([X_test_pairs[:, 0, :, :], \n",
    "                            X_test_pairs[:, 1, :, :]],\n",
    "                           y_test_pairs),\n",
    "          epochs=10,\n",
    "          batch_size=1024,\n",
    "          callbacks=[es])\n",
    "\n",
    "img_A, img_B = X_test[0], X_test[17]\n",
    "label_A, label_B = y_test[0], y_test[17]\n",
    "\n",
    "label_A, label_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b530e677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 168x112 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 168x112 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(dpi=28)\n",
    "plt.imshow(img_A)\n",
    "\n",
    "\n",
    "plt.figure(dpi=28)\n",
    "plt.imshow(img_B)\n",
    "\n",
    "\n",
    "model.predict([img_A.reshape((1, 28, 28)), \n",
    "               img_B.reshape((1, 28, 28))]).flatten()[0] > 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
